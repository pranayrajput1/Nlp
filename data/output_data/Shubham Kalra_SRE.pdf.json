{
    "name": "Shubham Kalra",
    "email": "Email:shubhamkalra22031994@gmail.com",
    "mobile_number": "2203199",
    "skills": [
        "Os",
        "Mysql",
        "English",
        "Scheduling",
        "Troubleshooting",
        "Ubuntu",
        "Cisco",
        "Vmware",
        "Docker",
        "Automation",
        "Ansible",
        "Windows",
        "Scripting",
        "Dns",
        "Cloud",
        "Technical skills",
        "Shell",
        "System",
        "Operations",
        "Linux",
        "Reports",
        "Aws",
        "Technical",
        "Servers"
    ],
    "college_name": null,
    "degree": [
        "B.Tech"
    ],
    "designation": [
        "Senior Analyst"
    ],
    "experience": [
        "goals by increasing the uptime and reliability of the product.",
        "Total Work Experience:  4.5+yrs",
        "Current Organization: Monotype Pvt. Ltd, Sector \u2013 125 Noida",
        "Duration: 27th September 2019 till date.",
        "Designation: SRE (Site Reliability Engineer II)",
        "Technologies:",
        "OS: RHEL, Ubuntu, Windows, MacOS(Mojave)",
        "Cloud Computing: AWS, Azure and GCP(Basics)",
        "Containerization: Kubernetes, Docker, ECS, EKS.",
        "Configuration Management Tool: Ansible.",
        "IAAC: Terraform.",
        "CI/CD: Jenkins.",
        "Versioning: Git.",
        "Web Server: Nginx, Apache.",
        "Monitoring Tools: Grafana, Prometheus, Cloudflare(Acts as a firewall, DNS, can set rate limiting rules), Kibana, New Relic, Cloudwatch, Datadog, Pingdom, Sites24*7,",
        "TICK, Nagios.",
        "Roles & Responsibilities :",
        "-  Creating and managing resources (EC2, ELB, ALB, NLB, VPC, RDS etc.) on AWS as well as on premise servers with help of Terraform, Ansible, Jenkins and other",
        "DevOps tools.",
        "-",
        "Setting up the whole application and infra level monitoring and alerting running on Kubernetes, EC2 instances and on-prem servers with the help of Grafana,",
        "Prometheus, Kibana, Site24x7, Cloudwatch, New Relic, Pingdom, DataDog and Nagios.",
        "-  Automating manual tasks with the help of shell.",
        "-",
        "Troubleshooting application related issues and infra level issues on Kubernetes, EC2 instances and on-prem servers.",
        "-  Working closely with DevOps members and creation of PPTs and reports on a quarterly basis in order to see how the product or application performed and",
        "creation of action items on the basis of the top talkers.",
        "-",
        "Installing monitoring tool agent on multiple servers using Ansible.",
        "-  Working closely with on call members, App team and DevOps team so as to get the RCAs of the issue.",
        "-  Upgrading the infra of applications that were hosted on legacy AWS servers.",
        "-",
        "Incident Escalation Policy creation and maintaining the complete Incident path.( from alerting state to resolution)",
        "Previous Organization: TO THE NEW (Intelligrape Software Pvt. Ltd.), Sector-144,Noida",
        "Duration : 13th November 2018 \u2013 26th September 2019",
        "Designation : Cloud Operations Engineer Technologies:",
        "OS: RHEL, Ubuntu,Windows. Cloud Computing: AWS Containerization:Kubernetes,Docker, ECS.",
        "Configuration Management Tool: Ansible.",
        "IAAC: Terraform",
        "CI/CD: Jenkins",
        "Versioning: Git",
        "Web Server: Nginx, Apache.",
        "Monitoring Tools: Nagios, Grafana, Kibana, New Relic, Cloudwatch, Datadog, Pingdom, Sites24*7, TICK.",
        "Responsibilities:",
        "-- Setting up alarms on cloudwatch through AWS CLI.",
        "-- Creating VPC, NAT, EC2, ALB, ELB, RDS from scratch for different Clients.",
        "-- Setting up Monitoring of multiple servers on Nagios, Grafana, Datadog.",
        "-- Managing IAM for multiple users and Roles.",
        "-- Used Ansible and its different modules to set up alarms, CWagent and deployment.",
        "-- Used Docker for multiple microservices.(Knowledge of Docker Compose, Docker Swarm)",
        "-- Used Jenkins for builds, ELK for logs.",
        "-- Worked on RDS degradation.",
        "-- Used shell scripting to automate the tasks as per the requirements.",
        "-- Knowledge of S3, Glacier, Cloudtrails for logs, Memcache, Redis, Auto Scaling, Load Balancing, Route 53, Cloudfront, STS,EBS.",
        "HCL Technologies Pvt. Ltd. Sector-126, Noida",
        "Role: - Senior Analyst",
        "Duration : (26th August 2016 - 5th November 2018) Roles & Responsibilities.",
        "SUMMARY:",
        "\u25cf  RHCSA certified (RHEL-7) \u2013 (180-162-794)",
        "\u25cf  Configuration and Management of Linux Servers.",
        "\u25cf",
        "\u25cf  Managing users, groups and permissions.",
        "LVM and RAID configurations.",
        "TECHNICAL SKILLS:",
        "\u25cf  Operating System: Linux (RHEL- 6, 7), Windows 7,8,10.",
        "\u25cf  Scripting: Basic knowledge of shell scripting.",
        "\u25cf  Tools: Coral (Automation Tool),Wireshark,Putty, Nagios , EM7, Remedy , VSphere, Vmware ,Nagios, Mysql workbench.",
        "\u25cf  Knowledge of RHCSA, RHCE, MYSQL, SNMP, NTP, DNS, YUM & RPM, ISCSI, TCP/IP and AWS.",
        "EXPERIENCE:",
        "Client/Project Name: CISCO",
        "Project Description: Production support is a team which handles all the CISCO internal applications. There are a set of applications handled by each individual. The",
        "individual is the owner of that application and has to take care of the complete working of the application.",
        "Responsibilities/Deliverables:",
        "\u25cf  Configuration and Management of Linux Servers.",
        "\u25cf  Performance and Network Monitoring using EM7, Nagios,VSphere.",
        "\u25cf  Creation and management of LVM .",
        "\u25cf  Resolving issues related to file system, swap memory and CPU usages.",
        "\u25cf  Managing NTP server configurations.",
        "\u25cf  Creation of SOP/MOP in order to reduce the resolution time.",
        "\u25cf  Optimized various day to day task for example : created backup removal cron job with",
        "the help of shell script.",
        "\u25cf  Creation of soft & hard links.",
        "\u25cf  Crontab Scheduling and Management.",
        "\u25cf",
        "Logs Management.",
        "Education:",
        "Examination  Board/University",
        "Subject",
        "Percentage  Year",
        "B.Tech",
        "KURUKSHETRA",
        "COMPUTER",
        "71",
        "2012-2016",
        "UNIVERSITY/Panipat",
        "& SCIENCE",
        "Institute of Enginereing &",
        "Technology",
        "12th",
        "10th",
        "CBSE",
        "CBSE",
        "Non-Medic",
        "67",
        "2012",
        "al",
        "NA",
        "76",
        "2010",
        "Personal Details:",
        "Date of birth",
        "Father\u2019s Name",
        "Nationality",
        "Languages Known",
        "Passport No",
        ":",
        ":",
        ":",
        ":",
        ":",
        "22/03/1994",
        "Mr.Chander Prakash Kalra",
        "Indian",
        "English & Hindi",
        "N3022183 valid till 10/09/2025",
        "Declaration: I hereby declare that the above information is true to the best of my knowledge."
    ],
    "company_names": [
        "HCL Technologies Pvt. Ltd."
    ],
    "no_of_pages": 7,
    "total_experience": 0.0
}