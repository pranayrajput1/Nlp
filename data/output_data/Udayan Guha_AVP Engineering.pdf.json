{
    "name": "UDAYAN GUHA",
    "email": "udayan.s.guha@gmail.com",
    "mobile_number": "9404901558",
    "skills": [
        "Tableau",
        "Nosql",
        "Project delivery",
        "Healthcare",
        "Ibm",
        "Python",
        "Scrum",
        "English",
        "Jira",
        "Unix",
        "Data analytics",
        "German",
        "Sales",
        "Banking",
        "Math",
        "Technical",
        "Acquisition",
        "Finance",
        "Algorithms",
        "Hospitality",
        "Analytics",
        "Engineering",
        "Oracle",
        "Matrix",
        "Standardization",
        "Hbase",
        "Retention",
        "Forecasting",
        "Data analysis",
        "Scripting",
        "Spark",
        "Analysis",
        "Design",
        "Strategy",
        "Business development",
        "Etl",
        "Coaching",
        "Analytical",
        "Machine learning",
        "Testing",
        "Hadoop",
        "Cloud",
        "Certification",
        "Retail",
        "Business intelligence",
        "Big data",
        "Shell",
        "Queries",
        "Sql",
        "Hive",
        "Agile",
        "R",
        "Operations",
        "Spanish",
        "Scala",
        "Computer science",
        "Sdlc",
        "Telecom",
        "Stakeholder management",
        "Aws",
        "Architecture",
        "Datasets",
        "Consulting"
    ],
    "college_name": null,
    "degree": [
        "B.E.",
        "udayan.s.guha@gmail.com"
    ],
    "designation": [
        "Lead Consultant"
    ],
    "experience": [
        "Since May\u201918 with Cotiviti India Pvt. Ltd., Pune as Tech Lead",
        "Project: Feature Library",
        "Period: Oct\u201918-Till Date",
        "Languages: Hadoop, Spark, Scala, Python, Ab Initio, Express IT, R, Hive, Kafka",
        "Tools: Mlflow, CI/CD Jenkins, Git, Tableau, DataRobot, Oozie,",
        "Key Result Areas:",
        "Spearheading  Data  Pipeline  and  Feature  Library  Engine  team  which  sources  data",
        "from  source  Ingestion  Layer  and  executes  business  rules  to  create  features  to  be",
        "used in machine learning models in department worth $ 20 M.",
        "Worked on strategic roadmap for data pipelines for current and future data sources",
        "Ab  Initio  Code  transformation  to  Spark/Scala  based  framework  to  create  data",
        "pipelines for Machine Learning teams, so that data can be used in ML models",
        "Successful laying of multi node architecture using Cloudera Hadoop for large volume",
        "data processing",
        "Implemented CI/CD pipeline for automated testing using DevOps",
        "Created NLP based solution to perform prediction of medical diagnosis code based",
        "on input data sets",
        "Processing complex and huge data sets using advanced queries, visualization and",
        "analytics.",
        "Performing  additional  role  of  scrum  master  and  handling  project  delivery  in  \u2018Agile",
        "framework\u2019",
        "Participating  in  Data  Preprocessing  Techniques  in  order  to  make  data  useful  for",
        "creating  Machine  Learning  Models;  using  Math\u2019s,  Stats  and  Machine  learning  to",
        "derive key insights for Operations Leaders",
        "Aug\u201916-Apr\u201918 with Hoonar Tekwurks Consulting LLP, Pune as Lead Consultant",
        "Project: Credit RISK",
        "Period: Oct\u201916-Sep\u201917",
        "Tools: Data Transformation, Ab Initio, Metadata HUB, Teradata, Hadoop, Hive,",
        "Cassandra NoSQL, Kibana, JIRA",
        "Key Result Areas:",
        "Worked as a technical lead and solution designer and design multidimensional data",
        "modelling using Erwin. Worked on Master Data Management for data standardization",
        "Developed end to end architecture of the project along with the laying of infrastructure,",
        "design of code and development of generic reusable code saving 20% resources.",
        "Successfully worked on POC of Cloud based solution using AWS.",
        "Created solution to fine-tune ETL code and implemented performance improvements",
        "in ETL code. Fine tuning saved 18% processing time and resources."
    ],
    "company_names": [
        "Oracle",
        "Shell"
    ],
    "no_of_pages": 2,
    "total_experience": 0.0
}