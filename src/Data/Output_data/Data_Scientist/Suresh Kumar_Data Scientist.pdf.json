{
    "name": "SURESH KUMAR",
    "email": "sureshynp9@gmail.com",
    "mobile_number": "9880420554",
    "skills": [
        "Machine learning",
        "Algorithms",
        "Numpy",
        "Testing",
        "Css",
        "Metrics",
        "Tableau",
        "Prototyping",
        "Hypothesis",
        "Scheduling",
        "Mining",
        "Python",
        "Writing",
        "Tensorflow",
        "Networking",
        "Django",
        "Matplotlib",
        "Data analysis",
        "Oracle",
        "Engineering",
        "Mysql",
        "Word",
        "Operations",
        "Hive",
        "R",
        "Etl",
        "Statistics",
        "Hadoop",
        "Windows",
        "Modeling",
        "Database",
        "Spacy",
        "Seaborn",
        "Nltk",
        "Scipy",
        "Html",
        "Computer applications",
        "Sql",
        "Documentation",
        "Analytical",
        "Analytics",
        "Process",
        "Email",
        "Training",
        "Linux",
        "Technical",
        "Forecasting",
        "Queries",
        "Analysis",
        "Pandas"
    ],
    "college_name": null,
    "degree": null,
    "designation": null,
    "experience": [
        "Used N-gram model and add and remove the stop words from the corpus to make Good prediction",
        "Used TF-IDF approach to give weights to words based on occurrences of a word",
        "Built a linear SVM classifier, naive Bayesian classifier to classify the text data.",
        "Analyzed the positive/negative sentiment for each given review to find out the like/dislike of the",
        "\u27a2",
        "Topic extraction.",
        "\u27a2",
        "on text data.",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "custom.",
        "\u27a2",
        "Model was evaluated using metrics such as accuracy, precision and recall",
        "Project 3: cluster Analysis",
        "Role:  Data Scientist",
        "Technologies: Machine learning techniques, MySQL, Python, Pandas, Numpy,Matplotlib",
        "Duration:  July 2019 to August 2020",
        "Responsibilities:",
        "Model was built with python, scikitlearn ,Pandas, Numpy, and matplotlib,Tableau.",
        "Worked with project team to understand the problem and business requirements.",
        "Converted all categorical data into continuous which will be used for modelling.",
        "Imported data into Python for exploring and understanding data",
        "Exploring the data and data structures for developing model",
        "Prepared data for creating training and test sets and data cleaning.",
        "Created a procedure to compute the cost of K-Means, this data was used to build a elbow chart to",
        "\u27a2",
        "The data employed involved 7 features that included Invoice No, StockCode , Description , Quantity,",
        "Invoice Date, Unit Price , Customer ID , Country and dataset having the Dim(4,000,7)with different set of",
        "customer\u2019s.",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "determine the optimum number of clusters to use.",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "Hierarchical Clustering, dendrogram.",
        "Model build on K-mean clustering, Agglomerative clustering and RFM model.",
        "Selected optimal number of clusters by elbow curve.",
        "Evaluate  and  selected  the  best  k-  cluster\u2019s  by  using  Hopkins  Statistics,  Silhouette  Analysis,",
        "Project 2: Churn prediction",
        "Role:  Data Scientist & Data Analyst",
        "Technologies: Machine learning techniques, MySQL, Tableau, python, NumPy, pandas, matplotlib",
        "Duration:  August 2017 to June 2019",
        "Responsibilities:",
        "Involving in the development of Python code, statistical/business model and its documentation.",
        "Identifying  the  relationships  between  multiple  variables  and  using  patterns  in  past  data  to shape",
        "\u27a2",
        "\u27a2",
        "insights.",
        "Internal Use - Confidential",
        "Explored and analyzed the customer specific features by using dashboards in Tableau and by making",
        "Worked on outliers\u2019 identification with box-plot, K-means clustering using Pandas, Numpy.",
        "Used Python 3.0 (numpy, scipy, pandas, scikit-learn, seaborn, NLTK) to develop variety of models",
        "Data  collection  from  various sources  and  validating  the  extracted  data  in  view  of  continuous  and",
        "Worked on outliers\u2019 identification with boxplot, K-means clustering using Pandas, Numpy.",
        "Participated in features engineering such as feature intersection generating, feature normalize and",
        "\u27a2",
        "categorical variables, along with checking for outliers and missing values.",
        "\u27a2",
        "\u27a2",
        "Label encoding with Scikit-learn preprocessing.",
        "\u27a2",
        "\u27a2",
        "and algorithms for analytic purposes.",
        "\u27a2",
        "visualizations using python",
        "\u27a2",
        "best models.",
        "\u27a2",
        "using Information Gain, Gini index, Entropy.",
        "\u27a2",
        "the models",
        "\u27a2",
        "data using techniques such as k-means clustering.",
        "Used K folded technique to compare the accuracies across the models and pushed the results of the",
        "Visualized the patterns of customers through decision tree. Identified the prioritized variables by",
        "Analysed the classification report, accuracy score and ROC& AUC curve to gauge the performance of",
        "Analyzed and grouped customers into different clusters based on customers purchase and historic",
        "Participated in features engineering such as feature intersection generating, feature normalize and",
        "Identified the TPR and FPR for the models.",
        "Resampling Methods: (CROSS-Validation and BootStrapping) to increase the accuracy of an Machine",
        "Involving in Decision tree model building Tree pruning, setting constraints on tree Size to make good",
        "Analyzed customer data for churn prediction using logistic regression, decision trees and Random",
        "After an effective feature reduction, the recall of the model was increased by 6%  and reach of the",
        "\u27a2",
        "Label encoding with Scikit-learn preprocessing.",
        "\u27a2",
        "\u27a2",
        "Learning Algorithm.",
        "\u27a2",
        "accuracy on test data.",
        "\u27a2",
        "Forests and done comparison on results",
        "\u27a2",
        "customer was increased by 11%",
        "Project 1: AIG -RM (Risk management Analysis)",
        "Role:  Hadoop Support Engineer",
        "Tools: Hadoop, Hive, Sqoop, Oozie, MySQL",
        "Duration:  January 2017 to July 2017",
        "Responsibilities:",
        "\u27a2",
        "services and solutions to the customer.",
        "\u27a2",
        "\u27a2",
        "Monitoring  the  CSM  SIM  job  tracking,  Analysis  enhancement  dashboard  to  better  provided  the",
        "Importing and exporting data into HDFS and RDMS using Sqoop.",
        "Involving in creating incident, service request ticket when the alert triggered over the dashboard.",
        "Internal Use - Confidential",
        "Managing long running jobs & huge cluster (Vcores/Memory) usage jobs and send the notification to",
        "\u27a2",
        "respective user.",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "\u27a2",
        "Edge node and Hadoop space checking and notifying to the team to take necessary actions.",
        "Creating the CR Task as requested by resolver teams and following up on to get CR approval.",
        "Having Good Knowledge in writing Map Reduce jobs in Hive.",
        "Monitoring the scheduling jobs in HDFS by using Oozie.",
        "Managed and reviewed Hadoop log files."
    ],
    "company_names": null,
    "no_of_pages": 5,
    "total_experience": 3.42
}