{
    "name": "Gargi Choudhary Systems Engineer",
    "email": null,
    "mobile_number": null,
    "skills": [
        "Scripting",
        "Oracle",
        "Hive",
        "Programming",
        "Hbase",
        "Technical",
        "Analysis",
        "Analytical",
        "Engineering",
        "Cloud",
        "Shell",
        "Json",
        "Testing",
        "Servers",
        "Automation",
        "Reconciliation",
        "Scrum",
        "Agile",
        "Transactions",
        "Writing",
        "Scheduling",
        "Sql",
        "Access",
        "Powerpoint",
        "Hadoop",
        "Scala",
        "Sales",
        "Jira",
        "Excel",
        "Design",
        "Warehouse",
        "Word",
        "Reporting",
        "Math",
        "Sdlc",
        "Spark",
        "Workflows",
        "Audit",
        "System",
        "Documentation",
        "Mysql",
        "Database",
        "English",
        "Java"
    ],
    "college_name": null,
    "degree": [
        "B.E. Computer Science and Engineering MBM Engineering college JNVU University"
    ],
    "designation": [
        "System Engineer",
        "Associate consultant Technology Experience Big Data Technologies Hadoop, HDFS, Hive, Spark, Sqoop, Oozie Programming Languages Scala, Java, Shell Scripting, SQL Tools IntellIJ, Eclipse, JIRA, Service now, GIT, Gerrit, Jenkins, Putty, WinSCP, Teradata SQL Assistant, SqlDeveloper, Ambari, Grafana, MS Office (Word, Excel, PowerPoint) Database  MySql Key Projects Role: Big Data Developer Technologies/Tools:Hadoop, Spark, Scala, Hive, Sqoop, Java, Shell Script, Oozie SDLC Model : Agile (SCRUM based) Description:Processing of raw data, pulled into Hadoop from various datasources, into business events and transaction for analytical insights through HDFS and Hiveusing secure framework based on Role based access control. Responsibilities:  Ingesting data from various source systems into Hadoop.  Writing sqoop scripts to ingest data from relational data sources like Teradata.  Maintaining different layers on hdfs like Landing, Raw, Consumption and Curated.  Validating the data files using java code against validation rules.  Writing HQL for creating and loading the data in hive tables from various source files like .txt, .csv,  json files and database like teradata, oracle.  Data Validation and Ingestion into Hive tables using Spark.  Involved in feature design, development and testing.  Creating Oozie shell and spark actions to run the Spark jobs  Time based scheduling of Oozie workflows   Involved in project deployment, support and Technical/Functional specification documentation  Coordinating between multiple cross-geography teams Project : MS Sales Role: MSBI Developer"
    ],
    "experience": null,
    "company_names": [
        "Microsoft"
    ],
    "no_of_pages": null,
    "total_experience": 0
}