{
    "name": "Harshan Rai",
    "email": "harshan.rai@gmail.com",
    "mobile_number": "8447778856",
    "skills": [
        "Os",
        "Ibm",
        "Networking",
        "Unix",
        "Java",
        "Inventory",
        "Updates",
        "Reporting",
        "Algorithms",
        "Engineering",
        "Oracle",
        "C",
        "Automation",
        "Training",
        "Windows",
        "Spark",
        "Design",
        "Access",
        "Programming",
        "Coding",
        "Etl",
        "Hadoop",
        "Database",
        "Redhat",
        "Sap",
        "Rest",
        "Shell",
        "Sql",
        "Android",
        "Hive",
        "Scala",
        "Warehouse",
        "Computer science",
        "Linux",
        "Reports",
        "Technical"
    ],
    "college_name": null,
    "degree": [
        "Bachelor of Technology, Computer Science & Engineering"
    ],
    "designation": null,
    "experience": [
        "IBM : Senior Technical Services Analyst, DBS Bank Singapore",
        "June\u201920 \u2013 Present",
        "\uf0a7  Recently joined IBM and been allocated to DBS Bank Singapore team.\uf020",
        "\uf0a7  Working as a Data Engineer for handling the Data Pipelines and their Spark-Scala codes.\uf020",
        "\uf0a7  Trained on new tools as per project requirements such as Alluxio, Apache Airflow, Collibra etc.\uf020",
        "\uf0a7  Handling data for stream processing through Kafka.\uf020",
        "\uf020",
        "Capgemini : Associate Consultant, TechnipFMC",
        "July\u201918 \u2013 May\u201920",
        "\uf0a7  Meetings with Clients and Managers to discuss and understand all major aspects of a new project, including",
        "scope, tasks required and deadlines\uf020",
        "\uf0a7  Provided L2/L3 support for all Hadoop related tools with respect to Data availability, Wrangling, Refresh",
        "frequency updates, and Metadata Cataloguing for our Datalake data to the Data Analysts.\uf020",
        "\uf0a7  Worked with Business and Data Analysts to understand their requirements and provide exceptional",
        "Automation and Configuration service requests\uf020",
        "\uf0a7  Performed data cleaning on unstructured information using Spark, Hive and wrangling tools like Trifacta\uf020",
        "\uf0a7  Created and analyzed different Hive Views and tables according to the Business requirements\uf020",
        "\uf0a7  Used Bucketed tables for transferring Postgres tables to Hive with the help of parallel Sqoop actions inside",
        "OOZIE Workflow\uf020",
        "\uf0a7  Contributed Scala code in generating UCOS-Project Data Pipeline through Apache Spark\uf020",
        "\uf0a7  Generated Spark jobs to facilitate data processing by using Spark-Submit inside Shell Scripts and scheduled",
        "them through NIFI flows or OOZIE Shell/Spark Action\uf020",
        "\uf0a7  Developed highly maintainable Shell and Scala codes following the best coding practices\uf020",
        "\uf0a7  Automated redundant tasks through Shell Script and NIFI\uf020",
        "\uf0a7  Scheduled Jobs/Scripts through Crontab and Oozie\uf020",
        "\uf0a7  Metadata Ingestion with their respective Data Classification Tags using Apache ATLAS Rest APIs\uf020",
        "(GET/POST)",
        "\uf0a7  Ensured that access to Hadoop clusters were secure and private by using Kerberos / Keytab Authentication in",
        "NIFI and other tools\uf020",
        "\uf0a7  Adopted and Skilled on new technologies to address changing Project and Client needs\uf020",
        "\uf0a7  Multi-tasked to keep all assigned tasks and jobs running effectively and efficiently\uf020",
        "Capgemini : Senior Analyst, PSA",
        "Oct\u201917 \u2013 June\u201918",
        "\uf0a7  Designed and modified ETL flows in Datastage to provide the required data coming from different raw",
        "materials warehouse sites\uf020",
        "\uf0a7  Managed  the  data  through  Oracle  Client  with  the  help  of  Universe  Design  Tool  (UDT)  and  Information\uf020",
        "Design Tool (IDT)",
        "\uf0a7  Created SAP BO Reports and modified previously built reports\uf020",
        "\uf0a7  Handled manufacturing parts inventory data coming from different sources to the Warehouse through Oracle",
        "database and ingesting them into different files/BI reports\uf020",
        "\uf0a7  Worked on different database tables to daily monitor the data of different sites and reporting it to our Lead",
        "and client for inaccuracy or irregularity of data\uf020",
        "\uf020",
        "INTERNSHIPS AND TRAININGS",
        "Capgemini: Unix, SQL, ETL, Reporting",
        "June\u201917 \u2013 Sept\u201917",
        "\uf0a7",
        "Initially, trained on Unix, SQL, ETL Basics and tools like DATASTAGE and SSRS in Capgemini.\uf020",
        "Ducat: Android Studio, Training & Project",
        "May\u201916 \u2013 July\u201916",
        "\uf0a7  Built a Java and Android project in graduation and also made some basic Android Applications.\uf020"
    ],
    "company_names": null,
    "no_of_pages": 2,
    "total_experience": 0.0
}