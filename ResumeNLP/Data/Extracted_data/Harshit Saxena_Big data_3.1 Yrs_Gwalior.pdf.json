{
    "name": "HARSHIT SAXENA",
    "email": "harshitprog05@gmail.com",
    "mobile_number": "0822404643",
    "skills": [
        "Aws",
        "Automation",
        "Html",
        "Email",
        "Rest",
        "Selenium",
        "Product development",
        "Sql",
        "Pattern",
        "Training",
        "Mysql",
        "Reporting",
        "Audit",
        "Technical",
        "Analyze",
        "Information technology",
        "Certification",
        "Spark",
        "Analytical",
        "Analytics",
        "Database",
        "Process",
        "Agile",
        "Api",
        "Engineering",
        "Architecture",
        "Statistical analysis",
        "Java",
        "Testing",
        "Governance",
        "Data analytics",
        "Analysis",
        "Access",
        "Etl",
        "Warehouse",
        "Scala"
    ],
    "college_name": null,
    "degree": null,
    "designation": null,
    "experience": [
        "PROJECT: Lumenore Data Layer (Product)                                                         [Oct'18- Present]",
        "Organization:  Netlink Software Group America Inc.",
        "An ETL Data Processing web based tool which has the capability to fetch data from multiple",
        "sources to the data warehouse, in this tool we are developing graphs and Jobs which consist of",
        "multiple transformations. This is tool is working as an ETL data pipeline for processing the data",
        "from 180+ data sources.",
        "ROLE                   :  Spark/Scala Developer",
        "TECHNOLOGIES:  Scala, Spark, Data frames, play framework, Rest API's, Kubernetes,",
        "Vertica, SBT, Spark SQL, RDD and MYSQL",
        "\uf0b7",
        "Leading, Managing, Planning and Designing the whole architecture of the product",
        "and involved in development of various types of transformation to aid a",
        "developer/user to perform data manipulation, data cleansing activities.",
        "\uf0b7  Prepared an organized data to provide proficient and valuable insights to customer.",
        "\uf0b7  Planned and designed the implementation and integration of data pipeline.",
        "\uf0b7  Performed a POC by setting up spark cluster on EC2 in AWS.",
        "\uf0b7  Overcame the challenges of storing & processing the structure, streaming and",
        "Unstructured data with the help of Spark, Kafka and Scala.",
        "\uf0b7  Configured various data connectors to fetch data from multiple sources including S3.",
        "\uf0b7  Also involved in setting up a spark-cluster using kubernetes resource manager.",
        "MANAGEMENT ROLE:",
        "\uf0b7",
        "source into Data warehouse.",
        "\uf0b7  Effort estimation and planning of task.",
        "Leading the team of 7 members to ingest the data from structured and unstructured"
    ],
    "company_names": null,
    "no_of_pages": 2,
    "total_experience": 0.0
}